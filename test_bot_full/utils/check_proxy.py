import os
import asyncio
import logging
import httpx
from openai import AsyncOpenAI

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–≥–µ—Ä–∞
logging.basicConfig(level=logging.INFO, format="%(asctime)s | %(levelname)s | %(message)s")

# –ü–æ–ª—É—á–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
OPENAI_PROXY = os.getenv("OPENAI_PROXY", "").strip()

logging.info(f"üîå OPENAI_PROXY: {repr(OPENAI_PROXY)}")

async def main():
    logging.info("üì§ –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫–ª–∏–µ–Ω—Ç–∞ httpx —Å –ø—Ä–æ–∫—Å–∏...")

    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Ç–∞–π–º–∞—É—Ç–æ–≤
    timeout = httpx.Timeout(30.0, connect=10.0)

    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø—Ä–æ–∫—Å–∏
    proxies = {"all://": OPENAI_PROXY} if OPENAI_PROXY else None
    async with httpx.AsyncClient(proxies=proxies, timeout=timeout) as http_client:
        logging.info("ü§ñ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–∞ OpenAI...")
        client = AsyncOpenAI(api_key=OPENAI_API_KEY, http_client=http_client)

        try:
            logging.info("‚úâÔ∏è –û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ GPT...")
            response = await asyncio.wait_for(
                client.chat.completions.create(
                    model="gpt-4o",
                    messages=[{"role": "user", "content": "–ù–∞–ø–∏—à–∏ –º–Ω–µ –∫–æ—Ä–æ—Ç–∫–∏–π –æ—Ç–≤–µ—Ç"}]
                ),
                timeout=25.0
            )
            answer = response.choices[0].message.content.strip()
            logging.info(f"‚úÖ –û—Ç–≤–µ—Ç –æ—Ç GPT: {answer}")
        except asyncio.TimeoutError:
            logging.error("‚è∞ –¢–∞–π–º–∞—É—Ç –æ–∂–∏–¥–∞–Ω–∏—è –æ—Ç–≤–µ—Ç–∞ –æ—Ç OpenAI.")
        except Exception as e:
            logging.error(f"‚ùå –û–±—â–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ OpenAI: {e}")
        finally:
            logging.info("üîí HTTP-–∫–ª–∏–µ–Ω—Ç –∑–∞–∫—Ä—ã—Ç.")

if __name__ == "__main__":
    asyncio.run(main())
