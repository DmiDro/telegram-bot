import os
import asyncio
import logging
import httpx
from openai import AsyncOpenAI

# === –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–≥–µ—Ä–∞ ===
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s | %(levelname)s | %(message)s"
)

# === –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è ===
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
OPENAI_PROXY = os.getenv("OPENAI_PROXY", "").strip()

# === –ü—Ä–∏–≤–µ–¥–µ–Ω–∏–µ —Å—Ö–µ–º—ã –ø—Ä–æ–∫—Å–∏ –∫ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º–æ–π —Ñ–æ—Ä–ºe (–µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω–∞ socks5h)
if OPENAI_PROXY.startswith("socks5h://"):
    OPENAI_PROXY = "socks5://" + OPENAI_PROXY[len("socks5h://"):]

logging.info(f"üîå OPENAI_PROXY: {repr(OPENAI_PROXY)}")

# === –¢–µ—Å—Ç–æ–≤–∞—è —Ñ—É–Ω–∫—Ü–∏—è ===
async def check_openai_via_proxy():
    try:
        http_client = httpx.AsyncClient(
            proxies={"all://": OPENAI_PROXY},
            timeout=30.0
        )

        client = AsyncOpenAI(
            api_key=OPENAI_API_KEY,
            http_client=http_client
        )

        prompt = "–ù–∞–ø–∏—à–∏ –º–Ω–µ –∫–æ—Ä–æ—Ç–∫–∏–π –æ—Ç–≤–µ—Ç"

        logging.info("üì§ –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –ø—Ä–æ–º—Ç –≤ OpenAI...")
        response = await client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": prompt}]
        )

        content = response.choices[0].message.content.strip()
        logging.info(f"‚úÖ –û—Ç–≤–µ—Ç –æ—Ç GPT:\n{content}")

    except Exception as e:
        logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–∏ —á–µ—Ä–µ–∑ –ø—Ä–æ–∫—Å–∏: {e}")

# === –ó–∞–ø—É—Å–∫ ===
if __name__ == "__main__":
    asyncio.run(check_openai_via_proxy())
