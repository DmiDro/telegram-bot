import os
import asyncio
import logging
import httpx
from openai import AsyncOpenAI

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–≥–µ—Ä–∞
logging.basicConfig(level=logging.INFO, format="%(asctime)s | %(levelname)s | %(message)s")

# –ü–æ–ª—É—á–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
OPENAI_PROXY = os.getenv("OPENAI_PROXY", "").strip()

# –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∞ –ø—Ä–æ–∫—Å–∏
if OPENAI_PROXY.startswith("socks5h://"):
    OPENAI_PROXY = "socks5://" + OPENAI_PROXY[len("socks5h://"):]

logging.info(f"üîå OPENAI_PROXY: {repr(OPENAI_PROXY)}")

# –û—Å–Ω–æ–≤–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞
async def main():
    logging.info("üì§ –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –∫ OpenAI —á–µ—Ä–µ–∑ –ø—Ä–æ–∫—Å–∏...")

    # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º httpx-–∫–ª–∏–µ–Ω—Ç —Å –ø—Ä–æ–∫—Å–∏
    http_client = httpx.AsyncClient(
        proxies={"all://": OPENAI_PROXY} if OPENAI_PROXY else None,
        timeout=30.0
    )

    # –°–æ–∑–¥–∞—ë–º –∫–ª–∏–µ–Ω—Ç–∞ OpenAI
    client = AsyncOpenAI(
        api_key=OPENAI_API_KEY,
        http_client=http_client
    )

    try:
        response = await client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": "–ù–∞–ø–∏—à–∏ –º–Ω–µ –∫–æ—Ä–æ—Ç–∫–∏–π –æ—Ç–≤–µ—Ç"}]
        )
        answer = response.choices[0].message.content.strip()
        logging.info(f"‚úÖ –û—Ç–≤–µ—Ç –æ—Ç GPT: {answer}")
    except Exception as e:
        logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ OpenAI: {e}")
    finally:
        await http_client.aclose()

# –ó–∞–ø—É—Å–∫
if __name__ == "__main__":
    asyncio.run(main())
