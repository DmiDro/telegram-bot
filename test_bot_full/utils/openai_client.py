import os
import logging
import asyncio
import httpx
from openai import AsyncOpenAI

# üîê Railway ‚Üí Set in Variables
OPENAI_API_KEY = os.environ["OPENAI_API_KEY"]
OPENAI_PROXY = os.environ.get("OPENAI_PROXY", "").strip()

# üëâ –û–±—Ä–∞–±–æ—Ç–∫–∞ socks5h:// ‚Üí socks5://
if OPENAI_PROXY.startswith("socks5h://"):
    OPENAI_PROXY = "socks5://" + OPENAI_PROXY[len("socks5h://"):]

# ‚úÖ httpx —Å –ø—Ä–æ–∫—Å–∏
http_client = httpx.AsyncClient(
    proxies={"all://": OPENAI_PROXY} if OPENAI_PROXY else None,
    timeout=httpx.Timeout(30.0)
)

# –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –∫–ª–∏–µ–Ω—Ç OpenAI
client = AsyncOpenAI(
    api_key=OPENAI_API_KEY,
    http_client=http_client
)

# –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞
async def generate_response(prompt: str, model: str = "gpt-4o") -> str:
    prompt_id = prompt.strip()[:60]
    try:
        logging.info(f"üì§ OpenAI: –æ—Ç–ø—Ä–∞–≤–∫–∞ prompt ({prompt_id})")
        response = await client.chat.completions.create(
            model=model,
            messages=[{"role": "user", "content": prompt.strip()}]
        )
        return response.choices[0].message.content.strip()

    except Exception as e:
        logging.critical(f"‚ùå –û—à–∏–±–∫–∞ OpenAI: {e}")
        return "‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç OpenAI."
